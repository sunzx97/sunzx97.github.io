<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>sunzx&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="sunzx&#39;s blog">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="sunzx&#39;s blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="sunzx">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="sunzx's blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">sunzx&#39;s blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-image-to-image" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/01/11/image-to-image/" class="article-date">
  <time class="dt-published" datetime="2023-01-10T16:16:21.000Z" itemprop="datePublished">2023-01-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/01/11/image-to-image/">image-to-image</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>让机器生成我们想要的图像是一件很酷的事情，本文总结一下图像生成的paper</p>
<h2 id="Generative-Adversarial-Nets-2014"><a href="#Generative-Adversarial-Nets-2014" class="headerlink" title="Generative Adversarial Nets[2014]"></a>Generative Adversarial Nets[2014]</h2><p>对于一般的任务比如图像识别我们有一个确定的类别来训练网络结构，将这成为判别算法。但是有一些情况是没有唯一真实标签的，比如我们只想生成带有数字的图片，至于这个数字是多少，数字写得好不好看不重要，只要是数字就行，也就是符合数字的这样一个特征分布，这时就没法直接用标签来训练网络结构了，于是引入了判别器，用于判断生成的分布是否与目标领域分布相同。<br>整个训练过程有必要了解<br><img src="/../images/gan_train.png"></p>
<h2 id="Conditional-Generative-Adversarial-Nets"><a href="#Conditional-Generative-Adversarial-Nets" class="headerlink" title="Conditional Generative Adversarial Nets"></a>Conditional Generative Adversarial Nets</h2><p>如果需要生成的不是整个目标图像域的随意一张图片，而是指定类别的图片呢，这时就需要额外添加控制变量<br><img src="/../images/cgan.png"></p>
<h2 id="Invertible-Conditional-GANs-for-image-editing"><a href="#Invertible-Conditional-GANs-for-image-editing" class="headerlink" title="Invertible Conditional GANs for image editing"></a>Invertible Conditional GANs for image editing</h2><p>更进一步，可不可以只改变图像的某些属性，而保留另外一些属性呢，比如给人脸换个发型<br><img src="/../images/icgan.png"></p>
<h2 id="Image-to-Image-Translation-with-Conditional-Adversarial-Networks"><a href="#Image-to-Image-Translation-with-Conditional-Adversarial-Networks" class="headerlink" title="Image-to-Image Translation with Conditional Adversarial Networks"></a>Image-to-Image Translation with Conditional Adversarial Networks</h2><p>一致性损失函数<br>$\mathcal{L}<em>{L 1}(G)&#x3D;\mathbb{E}</em>{x, y, z}\left[|y-G(x, z)|_1\right]$<br>encoder-decoder改成了u-net结构<br><img src="/../images/pix-to-pix-fra.png"><br>如果只让判别器分别是fake还是real太粗糙了，因此作者提出分块判别：This discriminator tries to classify if each N ×N patch in an image is real or fake. </p>
<h2 id="Unpaired-Image-to-Image-Translation-using-Cycle-Consistent-Adversarial-Networks"><a href="#Unpaired-Image-to-Image-Translation-using-Cycle-Consistent-Adversarial-Networks" class="headerlink" title="Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks"></a>Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</h2><p>闭环思路，不在需要成对的图像训练网络。<br><img src="/../images/cycle_gan.png"><br>另外需要特别注意的是为了防止 生成器G和生成器F互相包庇，需要引入 identity 损失函数，结合框架图就是 x 经过生成器 F 后生成的图像仍然是 x，而y经过生成器G后生成的图片仍然是y<br> $\mathcal{L}<em>{\text {identity }}(G, F)&#x3D;\mathbb{E}</em>{y \sim p_{\text {data }}(y)}\left[|G(y)-y|<em>1\right]+$ $\mathbb{E}</em>{x \sim p_{\text {data }}(x)}\left[|F(x)-x|_1\right]$</p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>更新中</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/01/11/image-to-image/" data-id="cloqxfcnn00030wu542c3aqha" data-title="image-to-image" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-semantic-segment-总结" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/01/08/semantic-segment-%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="dt-published" datetime="2023-01-08T07:17:43.000Z" itemprop="datePublished">2023-01-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/01/08/semantic-segment-%E6%80%BB%E7%BB%93/">semantic-segment-总结</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>因为参加了一个语义分割相关的项目，对语义分割方向的论文做一个大致的汇总。</p>
<h2 id="Fully-Convolutional-Networks-for-Semantic-Segmentation-2014"><a href="#Fully-Convolutional-Networks-for-Semantic-Segmentation-2014" class="headerlink" title="Fully Convolutional Networks for Semantic Segmentation[2014]"></a>Fully Convolutional Networks for Semantic Segmentation[2014]</h2><p>实现语义分割端到端训练的开山之作<br><img src="/../images/fcn.png"></p>
<h2 id="MULTI-SCALE-CONTEXT-AGGREGATION-BY-DILATED-CONVOLUTIONS-2015"><a href="#MULTI-SCALE-CONTEXT-AGGREGATION-BY-DILATED-CONVOLUTIONS-2015" class="headerlink" title="MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS[2015]"></a>MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS[2015]</h2><p>使用了空洞卷积，感觉如果是全局上下文比较重要的场景可以试试</p>
<h2 id="PARSENET-LOOKING-WIDER-TO-SEE-BETTER-2015"><a href="#PARSENET-LOOKING-WIDER-TO-SEE-BETTER-2015" class="headerlink" title="PARSENET: LOOKING WIDER TO SEE BETTER[2015]"></a>PARSENET: LOOKING WIDER TO SEE BETTER[2015]</h2><p>同样是从全局语义出发，当然文中提到了不同层的语义特征的尺度不同，因此在融合前需要进行归一化<br><img src="/../images/parsenet.png"></p>
<h2 id="Conditional-Random-Fields-as-Recurrent-Neural-Networks-2016"><a href="#Conditional-Random-Fields-as-Recurrent-Neural-Networks-2016" class="headerlink" title="Conditional Random Fields as Recurrent Neural Networks[2016]"></a>Conditional Random Fields as Recurrent Neural Networks[2016]</h2><p>将CRF思想融合到卷积中做语义分割的后处理，指标提升了不少，深入研究还有待看代码<br><img src="/../images/CNN_CRF.png"></p>
<h2 id="Large-Kernel-Matters-——-Improve-Semantic-Segmentation-by-Global-Convolutional-Network-2017"><a href="#Large-Kernel-Matters-——-Improve-Semantic-Segmentation-by-Global-Convolutional-Network-2017" class="headerlink" title="Large Kernel Matters —— Improve Semantic Segmentation by Global Convolutional Network[2017]"></a>Large Kernel Matters —— Improve Semantic Segmentation by Global Convolutional Network[2017]</h2><p>作者将语义分割分为分类与定位，然后提到分类是受感受野影响的，而设置更大的卷积核是有利于增大感受野的，关于语义分割任务的定位，我引用原文如下<br>Semantic segmentation can be considered as a per-pixel classification problem. There are two challenges in this task: 1) classification: an object associated to a specific semantic concept should be marked correctly; 2) localization: the classification label for a pixel must be aligned to the appropriate coordinates in output score map. A well-designed segmentation model should deal with the two issues simultaneously.<br>关于localization，我的理解就是自然规律，常识类信息，比如天空在上面<br>作者从提升分类效果出发，使用更大的卷积核，框架图如下<br><img src="/../images/global_gcn.png"><br>另外作者还展示了一篇研究真实感受野和理论感受野关系的论文，具体paper：OBJECT DETECTORS EMERGE IN DEEP SCENE CNNS<br><img src="/../images/reception.png"><br>另外作者关于感受野对分类重要性的举例也很有说服力<br><img src="/../images/reception_import.png"></p>
<h2 id="RefineNet-Multi-Path-Refinement-Networks-for-High-Resolution-Semantic-Segmentation-2017"><a href="#RefineNet-Multi-Path-Refinement-Networks-for-High-Resolution-Semantic-Segmentation-2017" class="headerlink" title="RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation[2017]"></a>RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation[2017]</h2><p>整体思路还是利用底层特征<br><img src="/../images/refine_net.png"><br>具体框架图<br><img src="/../images/refine_net_fra.png"></p>
<h2 id="Pyramid-Scene-Parsing-Network-2017"><a href="#Pyramid-Scene-Parsing-Network-2017" class="headerlink" title="Pyramid Scene Parsing Network[2017]"></a>Pyramid Scene Parsing Network[2017]</h2><p>同样是金字塔的方式利用全局信息及深层次语义信息<br><img src="/../images/psp_net.png"></p>
<h2 id="Rethinking-Atrous-Convolution-for-Semantic-Image-Segmentation-2017"><a href="#Rethinking-Atrous-Convolution-for-Semantic-Image-Segmentation-2017" class="headerlink" title="Rethinking Atrous Convolution for Semantic Image Segmentation[2017]"></a>Rethinking Atrous Convolution for Semantic Image Segmentation[2017]</h2><p>以空洞卷积的方式融合全局信息, 虽然思路和前面的文章大差不差，但本文的related work 做了很详细的总结，值得品读。<br><img src="/../images/deeplab_v3.png"></p>
<h2 id="Encoder-Decoder-with-Atrous-Separable-Convolution-for-Semantic-Image-Segmentation-2018"><a href="#Encoder-Decoder-with-Atrous-Separable-Convolution-for-Semantic-Image-Segmentation-2018" class="headerlink" title="Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation[2018]"></a>Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation[2018]</h2><p>在deeplab-v3的基础上添加编解码器结构进一步融合底层特征，论文从形状信息来表述<br><img src="/../images/deeplab_v3_plus.png"><br><img src="/../images/deeplab_v3_plus_fra.png"></p>
<p>更新中</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/01/08/semantic-segment-%E6%80%BB%E7%BB%93/" data-id="cloqxfcnv00080wu51ejs5pd9" data-title="semantic-segment-总结" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-resnet系列" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/01/07/resnet%E7%B3%BB%E5%88%97/" class="article-date">
  <time class="dt-published" datetime="2023-01-07T05:08:01.000Z" itemprop="datePublished">2023-01-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/01/07/resnet%E7%B3%BB%E5%88%97/">resnet系列</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>resnet系列任然是很多计算机视觉任务的backbone，本文从论文和代码角度对其进行讲解。</p>
<h2 id="Deep-Residual-Learning-for-Image-Recognition"><a href="#Deep-Residual-Learning-for-Image-Recognition" class="headerlink" title="Deep Residual Learning for Image Recognition"></a>Deep Residual Learning for Image Recognition</h2><p>ResNet解决的是网络退化问题（注意不是梯度消失或爆炸），什么是网络退化见下图<br><img src="/../images/resnet_pri.png"><br>不同深度的网络结构如下<br><img src="/../images/resnet_framework.png"><br>注意每层的第一个block的stride是可以是2或1，剩下的block是1<br>代码参见：<a target="_blank" rel="noopener" href="https://github.com/weiaicunzai/pytorch-cifar100/tree/master/models">https://github.com/weiaicunzai/pytorch-cifar100/tree/master/models</a><br>值得注意的是残差连接需要考虑通道数不同与由于stride导致的大小不同的情况</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;resnet in pytorch</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Deep Residual Learning for Image Recognition</span></span><br><span class="line"><span class="string">    https://arxiv.org/abs/1512.03385v1</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Basic Block for resnet 18 and resnet 34</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#BasicBlock and BottleNeck block</span></span><br><span class="line">    <span class="comment">#have different output size</span></span><br><span class="line">    <span class="comment">#we use class attribute expansion</span></span><br><span class="line">    <span class="comment">#to distinct</span></span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#residual function</span></span><br><span class="line">        self.residual_function = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels * BasicBlock.expansion)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment">#shortcut</span></span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#the shortcut output dimension is not the same with residual function</span></span><br><span class="line">        <span class="comment">#use 1*1 convolution to match the dimension</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_channels != BasicBlock.expansion * out_channels:</span><br><span class="line">            self.shortcut = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(out_channels * BasicBlock.expansion)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> nn.ReLU(inplace=<span class="literal">True</span>)(self.residual_function(x) + self.shortcut(x))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BottleNeck</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Residual block for resnet over 50 layers</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.residual_function = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels * BottleNeck.expansion),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_channels != out_channels * BottleNeck.expansion:</span><br><span class="line">            self.shortcut = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(out_channels * BottleNeck.expansion)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> nn.ReLU(inplace=<span class="literal">True</span>)(self.residual_function(x) + self.shortcut(x))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, num_block, num_classes=<span class="number">100</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.in_channels = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">        <span class="comment">#we use a different inputsize than the original paper</span></span><br><span class="line">        <span class="comment">#so conv2_x&#x27;s stride is 1</span></span><br><span class="line">        self.conv2_x = self._make_layer(block, <span class="number">64</span>, num_block[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">        self.conv3_x = self._make_layer(block, <span class="number">128</span>, num_block[<span class="number">1</span>], <span class="number">2</span>)</span><br><span class="line">        self.conv4_x = self._make_layer(block, <span class="number">256</span>, num_block[<span class="number">2</span>], <span class="number">2</span>)</span><br><span class="line">        self.conv5_x = self._make_layer(block, <span class="number">512</span>, num_block[<span class="number">3</span>], <span class="number">2</span>)</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, out_channels, num_blocks, stride</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;make resnet layers(by layer i didnt mean this &#x27;layer&#x27; was the</span></span><br><span class="line"><span class="string">        same as a neuron netowork layer, ex. conv layer), one layer may</span></span><br><span class="line"><span class="string">        contain more than one residual block</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            block: block type, basic block or bottle neck block</span></span><br><span class="line"><span class="string">            out_channels: output depth channel number of this layer</span></span><br><span class="line"><span class="string">            num_blocks: how many blocks per layer</span></span><br><span class="line"><span class="string">            stride: the stride of the first block of this layer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            return a resnet layer</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># we have num_block blocks per layer, the first block</span></span><br><span class="line">        <span class="comment"># could be 1 or 2, other blocks would always be 1</span></span><br><span class="line">        strides = [stride] + [<span class="number">1</span>] * (num_blocks - <span class="number">1</span>)</span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">for</span> stride <span class="keyword">in</span> strides:</span><br><span class="line">            layers.append(block(self.in_channels, out_channels, stride))</span><br><span class="line">            self.in_channels = out_channels * block.expansion</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        output = self.conv1(x)</span><br><span class="line">        output = self.conv2_x(output)</span><br><span class="line">        output = self.conv3_x(output)</span><br><span class="line">        output = self.conv4_x(output)</span><br><span class="line">        output = self.conv5_x(output)</span><br><span class="line">        output = self.avg_pool(output)</span><br><span class="line">        output = output.view(output.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        output = self.fc(output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet18</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; return a ResNet 18 object</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet34</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; return a ResNet 34 object</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet50</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; return a ResNet 50 object</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BottleNeck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet101</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; return a ResNet 101 object</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BottleNeck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnet152</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; return a ResNet 152 object</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BottleNeck, [<span class="number">3</span>, <span class="number">8</span>, <span class="number">36</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Aggregated-Residual-Transformations-for-Deep-Neural-Networks"><a href="#Aggregated-Residual-Transformations-for-Deep-Neural-Networks" class="headerlink" title="Aggregated Residual Transformations for Deep Neural Networks"></a>Aggregated Residual Transformations for Deep Neural Networks</h2><p>基于ResNet，另一个被广泛使用的backbone是ResNeXt，其原理图如下<br><img src="/../images/resnxt_pri.png"><br>ResNext基本是在ResNet的基础上在通道上进行划分，在代码上通过的group参数可以快速实现，其网络结构与ResNet同步<br><img src="/../images/resnext.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;resnext in pytorch</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[1] Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Aggregated Residual Transformations for Deep Neural Networks</span></span><br><span class="line"><span class="string">    https://arxiv.org/abs/1611.05431</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment">#only implements ResNext bottleneck c</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#&quot;&quot;&quot;This strategy exposes a new dimension, which we call “cardinality”</span></span><br><span class="line"><span class="comment">#(the size of the set of transformations), as an essential factor</span></span><br><span class="line"><span class="comment">#in addition to the dimensions of depth and width.&quot;&quot;&quot;</span></span><br><span class="line">CARDINALITY = <span class="number">32</span></span><br><span class="line">DEPTH = <span class="number">4</span></span><br><span class="line">BASEWIDTH = <span class="number">64</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#&quot;&quot;&quot;The grouped convolutional layer in Fig. 3(c) performs 32 groups</span></span><br><span class="line"><span class="comment">#of convolutions whose input and output channels are 4-dimensional.</span></span><br><span class="line"><span class="comment">#The grouped convolutional layer concatenates them as the outputs</span></span><br><span class="line"><span class="comment">#of the layer.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNextBottleNeckC</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, stride</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        C = CARDINALITY <span class="comment">#How many groups a feature map was splitted into</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#&quot;&quot;&quot;We note that the input/output width of the template is fixed as</span></span><br><span class="line">        <span class="comment">#256-d (Fig. 3), We note that the input/output width of the template</span></span><br><span class="line">        <span class="comment">#is fixed as 256-d (Fig. 3), and all widths are dou- bled each time</span></span><br><span class="line">        <span class="comment">#when the feature map is subsampled (see Table 1).&quot;&quot;&quot;</span></span><br><span class="line">        D = <span class="built_in">int</span>(DEPTH * out_channels / BASEWIDTH) <span class="comment">#number of channels per group</span></span><br><span class="line">        self.split_transforms = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, C * D, kernel_size=<span class="number">1</span>, groups=C, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(C * D),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(C * D, C * D, kernel_size=<span class="number">3</span>, stride=stride, groups=C, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(C * D),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(C * D, out_channels * <span class="number">4</span>, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels * <span class="number">4</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_channels != out_channels * <span class="number">4</span>:</span><br><span class="line">            self.shortcut = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels, out_channels * <span class="number">4</span>, stride=stride, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(out_channels * <span class="number">4</span>)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> F.relu(self.split_transforms(x) + self.shortcut(x))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNext</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, num_blocks, class_names=<span class="number">100</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.in_channels = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.conv2 = self._make_layer(block, num_blocks[<span class="number">0</span>], <span class="number">64</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv3 = self._make_layer(block, num_blocks[<span class="number">1</span>], <span class="number">128</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv4 = self._make_layer(block, num_blocks[<span class="number">2</span>], <span class="number">256</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv5 = self._make_layer(block, num_blocks[<span class="number">3</span>], <span class="number">512</span>, <span class="number">2</span>)</span><br><span class="line">        self.avg = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span> * <span class="number">4</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = self.conv4(x)</span><br><span class="line">        x = self.conv5(x)</span><br><span class="line">        x = self.avg(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self, block, num_block, out_channels, stride</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Building resnext block</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            block: block type(default resnext bottleneck c)</span></span><br><span class="line"><span class="string">            num_block: number of blocks per layer</span></span><br><span class="line"><span class="string">            out_channels: output channels per block</span></span><br><span class="line"><span class="string">            stride: block stride</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            a resnext layer</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        strides = [stride] + [<span class="number">1</span>] * (num_block - <span class="number">1</span>)</span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">for</span> stride <span class="keyword">in</span> strides:</span><br><span class="line">            layers.append(block(self.in_channels, out_channels, stride))</span><br><span class="line">            self.in_channels = out_channels * <span class="number">4</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnext50</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; return a resnext50(c32x4d) network</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> ResNext(ResNextBottleNeckC, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnext101</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; return a resnext101(c32x4d) network</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> ResNext(ResNextBottleNeckC, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resnext152</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; return a resnext101(c32x4d) network</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> ResNext(ResNextBottleNeckC, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">36</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/01/07/resnet%E7%B3%BB%E5%88%97/" data-id="cloqxfcnu00070wu598v04wkh" data-title="resnet系列" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-downloader" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/01/02/downloader/" class="article-date">
  <time class="dt-published" datetime="2023-01-02T14:52:23.000Z" itemprop="datePublished">2023-01-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/01/02/downloader/">downloader</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>一个简易的爬虫项目，用于下载网上的一些pdf资料。涉及到异步库，redis等知识。</p>
<h2 id="asyncio"><a href="#asyncio" class="headerlink" title="asyncio"></a>asyncio</h2><p>对asyncio只有一个基本认识，一个异步框架。主要包括Eventloop, Coroutine(协程), Future, Task四个基础概念。既然要做到异步，肯定涉及到事件循环调用，而Eventloop就相当与控制中心，负责循环调用注册在其中的协程。而coroutine(协程)是一种特殊的函数，特殊在于其可以交出调用权。Future是对Coroutine的再封装，而Task提供了一套接口方便开发者创建Future。协程可以通过yield实现交出调用权。<br>参考：<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/72887901">https://zhuanlan.zhihu.com/p/72887901</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/73568282">https://zhuanlan.zhihu.com/p/73568282</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/75193842">https://zhuanlan.zhihu.com/p/75193842</a></p>
<h2 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h2><p>redis是一个内存型数据库，为了业务需求提供了一些特定的数据结构，在一些业务场景使用广泛，这里主要是用redis的列表结构保存即将要访问的链接。在python中使用redis如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">r = redis.StrictRedis(host=<span class="string">&#x27;127.0.0.1&#x27;</span>, port=<span class="number">6379</span>, db=<span class="number">2</span>, decode_responses=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 创建一名为url_list的列表，并添加item</span></span><br><span class="line">r.lpush(<span class="string">&#x27;url_list&#x27;</span>, item)</span><br><span class="line"><span class="comment"># pop 一项 item</span></span><br><span class="line">r.rpop(<span class="string">&#x27;url_list&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>另外本文使用redis实现 bloom filter，参见：<a target="_blank" rel="noopener" href="https://github.com/HatBoy/BloomFilter">https://github.com/HatBoy/BloomFilter</a><br>关于 bloom filter的原理，一张图就足够清晰了<br><img src="/../images/bloom_filter.gif"><br>由bloom filter的原理可知，错误率由数组的长度和 hash 函数数量决定，但在设定的时候这些东西很间接，没什么概率，但我们大概需要存多少数据，要控制在什么样的错误率下这些是直接的，于是根据这些直接的值计算出数组长度和hash函数个数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> mmh3</span><br><span class="line"><span class="keyword">import</span> BitVector</span><br><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BloomFilter</span>():</span><br><span class="line">    <span class="comment">#内置100个随机种子</span></span><br><span class="line">    SEEDS = [<span class="number">543</span>, <span class="number">460</span>, <span class="number">171</span>, <span class="number">876</span>, <span class="number">796</span>, <span class="number">607</span>, <span class="number">650</span>, <span class="number">81</span>, <span class="number">837</span>, <span class="number">545</span>, <span class="number">591</span>, <span class="number">946</span>, <span class="number">846</span>, <span class="number">521</span>, <span class="number">913</span>, <span class="number">636</span>, <span class="number">878</span>, <span class="number">735</span>, <span class="number">414</span>, <span class="number">372</span>,</span><br><span class="line">             <span class="number">344</span>, <span class="number">324</span>, <span class="number">223</span>, <span class="number">180</span>, <span class="number">327</span>, <span class="number">891</span>, <span class="number">798</span>, <span class="number">933</span>, <span class="number">493</span>, <span class="number">293</span>, <span class="number">836</span>, <span class="number">10</span>, <span class="number">6</span>, <span class="number">544</span>, <span class="number">924</span>, <span class="number">849</span>, <span class="number">438</span>, <span class="number">41</span>, <span class="number">862</span>, <span class="number">648</span>, <span class="number">338</span>,</span><br><span class="line">             <span class="number">465</span>, <span class="number">562</span>, <span class="number">693</span>, <span class="number">979</span>, <span class="number">52</span>, <span class="number">763</span>, <span class="number">103</span>, <span class="number">387</span>, <span class="number">374</span>, <span class="number">349</span>, <span class="number">94</span>, <span class="number">384</span>, <span class="number">680</span>, <span class="number">574</span>, <span class="number">480</span>, <span class="number">307</span>, <span class="number">580</span>, <span class="number">71</span>, <span class="number">535</span>, <span class="number">300</span>, <span class="number">53</span>,</span><br><span class="line">             <span class="number">481</span>, <span class="number">519</span>, <span class="number">644</span>, <span class="number">219</span>, <span class="number">686</span>, <span class="number">236</span>, <span class="number">424</span>, <span class="number">326</span>, <span class="number">244</span>, <span class="number">212</span>, <span class="number">909</span>, <span class="number">202</span>, <span class="number">951</span>, <span class="number">56</span>, <span class="number">812</span>, <span class="number">901</span>, <span class="number">926</span>, <span class="number">250</span>, <span class="number">507</span>, <span class="number">739</span>, <span class="number">371</span>,</span><br><span class="line">             <span class="number">63</span>, <span class="number">584</span>, <span class="number">154</span>, <span class="number">7</span>, <span class="number">284</span>, <span class="number">617</span>, <span class="number">332</span>, <span class="number">472</span>, <span class="number">140</span>, <span class="number">605</span>, <span class="number">262</span>, <span class="number">355</span>, <span class="number">526</span>, <span class="number">647</span>, <span class="number">923</span>, <span class="number">199</span>, <span class="number">518</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#capacity是预先估计要去重的数量</span></span><br><span class="line">    <span class="comment">#error_rate表示错误率</span></span><br><span class="line">    <span class="comment">#conn表示redis的连接客户端</span></span><br><span class="line">    <span class="comment">#key表示在redis中的键的名字前缀</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, capacity=<span class="number">1000000000</span>, error_rate=<span class="number">0.00000001</span>, conn=<span class="literal">None</span>, key=<span class="string">&#x27;BloomFilter&#x27;</span></span>):</span><br><span class="line">        self.m = math.ceil(capacity*math.log2(math.e)*math.log2(<span class="number">1</span>/error_rate))      <span class="comment">#需要的总bit位数</span></span><br><span class="line">        self.k = math.ceil(math.log1p(<span class="number">2</span>)*self.m/capacity)                           <span class="comment">#需要最少的hash次数</span></span><br><span class="line">        self.mem = math.ceil(self.m/<span class="number">8</span>/<span class="number">1024</span>/<span class="number">1024</span>)                                    <span class="comment">#需要的多少M内存</span></span><br><span class="line">        self.blocknum = math.ceil(self.mem/<span class="number">512</span>)                                     <span class="comment">#需要多少个512M的内存块,value的第一个字符必须是ascii码，所有最多有256个内存块</span></span><br><span class="line">        self.seeds = self.SEEDS[<span class="number">0</span>:self.k]</span><br><span class="line">        self.key = key</span><br><span class="line">        self.N = <span class="number">2</span>**<span class="number">31</span>-<span class="number">1</span></span><br><span class="line">        self.redis = conn</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.redis:</span><br><span class="line">            <span class="comment">#默认如果没有redis连接，在内存中使用512M的内存块去重</span></span><br><span class="line">            self.bitset = BitVector.BitVector(size=<span class="number">1</span>&lt;&lt;<span class="number">32</span>)</span><br><span class="line">        <span class="built_in">print</span>(self.mem)</span><br><span class="line">        <span class="built_in">print</span>(self.k)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, value</span>):</span><br><span class="line">        name = self.key + <span class="string">&quot;_&quot;</span> + <span class="built_in">str</span>(<span class="built_in">ord</span>(value[<span class="number">0</span>])%self.blocknum)</span><br><span class="line">        hashs = self.get_hashs(value)</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">hash</span> <span class="keyword">in</span> hashs:</span><br><span class="line">            <span class="keyword">if</span> self.redis:</span><br><span class="line">                self.redis.setbit(name, <span class="built_in">hash</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.bitset[<span class="built_in">hash</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_exist</span>(<span class="params">self, value</span>):</span><br><span class="line">        name = self.key + <span class="string">&quot;_&quot;</span> + <span class="built_in">str</span>(<span class="built_in">ord</span>(value[<span class="number">0</span>])%self.blocknum)</span><br><span class="line">        hashs = self.get_hashs(value)</span><br><span class="line">        exist = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">hash</span> <span class="keyword">in</span> hashs:</span><br><span class="line">            <span class="keyword">if</span> self.redis:</span><br><span class="line">                exist = exist &amp; self.redis.getbit(name, <span class="built_in">hash</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                exist = exist &amp; self.bitset[<span class="built_in">hash</span>]</span><br><span class="line">        <span class="keyword">return</span> exist</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_hashs</span>(<span class="params">self, value</span>):</span><br><span class="line">        hashs = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> seed <span class="keyword">in</span> self.seeds:</span><br><span class="line">            <span class="built_in">hash</span> = mmh3.<span class="built_in">hash</span>(value, seed)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hash</span> &gt;= <span class="number">0</span>:</span><br><span class="line">                hashs.append(<span class="built_in">hash</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                hashs.append(self.N - <span class="built_in">hash</span>)</span><br><span class="line">        <span class="keyword">return</span> hashs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pool = redis.ConnectionPool(host=<span class="string">&#x27;127.0.0.1&#x27;</span>, port=<span class="number">6379</span>, db=<span class="number">0</span>)</span><br><span class="line">conn = redis.StrictRedis(connection_pool=pool)</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line">bf = BloomFilter(conn=conn)</span><br><span class="line">bf.add(<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">bf.add(<span class="string">&#x27;fsest1&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(bf.is_exist(<span class="string">&#x27;qest&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(bf.is_exist(<span class="string">&#x27;testdsad&#x27;</span>))</span><br><span class="line">end = time.time()</span><br><span class="line"><span class="built_in">print</span>(end-start)</span><br></pre></td></tr></table></figure>
<h2 id="downloader"><a href="#downloader" class="headerlink" title="downloader"></a>downloader</h2><p>以下创建一个简易爬虫，给定初始网址后该爬虫自动提取网页中的其他网址，并不断往下访问。如果链接是以pdf结尾则进行下载(如果要下载图片或其他资源原理相同)。这个版本代码没有考虑网页中的相对路径地址，以后有时间再写第二个版本吧。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="keyword">as</span> bs</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"><span class="keyword">import</span> mmh3</span><br><span class="line"><span class="keyword">from</span> bitarray <span class="keyword">import</span> bitarray</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> BitVector</span><br><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">proxies = &#123;<span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://127.0.0.1:7890&#x27;</span>, <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;http://127.0.0.1:7890&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BloomFilter</span>():</span><br><span class="line">    <span class="comment">#内置100个随机种子</span></span><br><span class="line">    SEEDS = [<span class="number">543</span>, <span class="number">460</span>, <span class="number">171</span>, <span class="number">876</span>, <span class="number">796</span>, <span class="number">607</span>, <span class="number">650</span>, <span class="number">81</span>, <span class="number">837</span>, <span class="number">545</span>, <span class="number">591</span>, <span class="number">946</span>, <span class="number">846</span>, <span class="number">521</span>, <span class="number">913</span>, <span class="number">636</span>, <span class="number">878</span>, <span class="number">735</span>, <span class="number">414</span>, <span class="number">372</span>,</span><br><span class="line">             <span class="number">344</span>, <span class="number">324</span>, <span class="number">223</span>, <span class="number">180</span>, <span class="number">327</span>, <span class="number">891</span>, <span class="number">798</span>, <span class="number">933</span>, <span class="number">493</span>, <span class="number">293</span>, <span class="number">836</span>, <span class="number">10</span>, <span class="number">6</span>, <span class="number">544</span>, <span class="number">924</span>, <span class="number">849</span>, <span class="number">438</span>, <span class="number">41</span>, <span class="number">862</span>, <span class="number">648</span>, <span class="number">338</span>,</span><br><span class="line">             <span class="number">465</span>, <span class="number">562</span>, <span class="number">693</span>, <span class="number">979</span>, <span class="number">52</span>, <span class="number">763</span>, <span class="number">103</span>, <span class="number">387</span>, <span class="number">374</span>, <span class="number">349</span>, <span class="number">94</span>, <span class="number">384</span>, <span class="number">680</span>, <span class="number">574</span>, <span class="number">480</span>, <span class="number">307</span>, <span class="number">580</span>, <span class="number">71</span>, <span class="number">535</span>, <span class="number">300</span>, <span class="number">53</span>,</span><br><span class="line">             <span class="number">481</span>, <span class="number">519</span>, <span class="number">644</span>, <span class="number">219</span>, <span class="number">686</span>, <span class="number">236</span>, <span class="number">424</span>, <span class="number">326</span>, <span class="number">244</span>, <span class="number">212</span>, <span class="number">909</span>, <span class="number">202</span>, <span class="number">951</span>, <span class="number">56</span>, <span class="number">812</span>, <span class="number">901</span>, <span class="number">926</span>, <span class="number">250</span>, <span class="number">507</span>, <span class="number">739</span>, <span class="number">371</span>,</span><br><span class="line">             <span class="number">63</span>, <span class="number">584</span>, <span class="number">154</span>, <span class="number">7</span>, <span class="number">284</span>, <span class="number">617</span>, <span class="number">332</span>, <span class="number">472</span>, <span class="number">140</span>, <span class="number">605</span>, <span class="number">262</span>, <span class="number">355</span>, <span class="number">526</span>, <span class="number">647</span>, <span class="number">923</span>, <span class="number">199</span>, <span class="number">518</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#capacity是预先估计要去重的数量</span></span><br><span class="line">    <span class="comment">#error_rate表示错误率</span></span><br><span class="line">    <span class="comment">#conn表示redis的连接客户端</span></span><br><span class="line">    <span class="comment">#key表示在redis中的键的名字前缀</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, capacity=<span class="number">1000000000</span>, error_rate=<span class="number">0.00000001</span>, conn=<span class="literal">None</span>, key=<span class="string">&#x27;BloomFilter&#x27;</span></span>):</span><br><span class="line">        self.m = math.ceil(capacity*math.log2(math.e)*math.log2(<span class="number">1</span>/error_rate))      <span class="comment">#需要的总bit位数</span></span><br><span class="line">        self.k = math.ceil(math.log1p(<span class="number">2</span>)*self.m/capacity)                           <span class="comment">#需要最少的hash次数</span></span><br><span class="line">        self.mem = math.ceil(self.m/<span class="number">8</span>/<span class="number">1024</span>/<span class="number">1024</span>)                                    <span class="comment">#需要的多少M内存</span></span><br><span class="line">        self.blocknum = math.ceil(self.mem/<span class="number">512</span>)                                     <span class="comment">#需要多少个512M的内存块,value的第一个字符必须是ascii码，所有最多有256个内存块</span></span><br><span class="line">        self.seeds = self.SEEDS[<span class="number">0</span>:self.k]</span><br><span class="line">        self.key = key</span><br><span class="line">        self.N = <span class="number">2</span>**<span class="number">31</span>-<span class="number">1</span></span><br><span class="line">        self.redis = conn</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.redis:</span><br><span class="line">            <span class="comment">#默认如果没有redis连接，在内存中使用512M的内存块去重</span></span><br><span class="line">            self.bitset = BitVector.BitVector(size=<span class="number">1</span>&lt;&lt;<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, value</span>):</span><br><span class="line">        name = self.key + <span class="string">&quot;_&quot;</span> + <span class="built_in">str</span>(<span class="built_in">ord</span>(value[<span class="number">0</span>])%self.blocknum)</span><br><span class="line">        hashs = self.get_hashs(value)</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">hash</span> <span class="keyword">in</span> hashs:</span><br><span class="line">            <span class="keyword">if</span> self.redis:</span><br><span class="line">                self.redis.setbit(name, <span class="built_in">hash</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.bitset[<span class="built_in">hash</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_exist</span>(<span class="params">self, value</span>):</span><br><span class="line">        name = self.key + <span class="string">&quot;_&quot;</span> + <span class="built_in">str</span>(<span class="built_in">ord</span>(value[<span class="number">0</span>])%self.blocknum)</span><br><span class="line">        hashs = self.get_hashs(value)</span><br><span class="line">        exist = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">hash</span> <span class="keyword">in</span> hashs:</span><br><span class="line">            <span class="keyword">if</span> self.redis:</span><br><span class="line">                exist = exist &amp; self.redis.getbit(name, <span class="built_in">hash</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                exist = exist &amp; self.bitset[<span class="built_in">hash</span>]</span><br><span class="line">        <span class="keyword">return</span> exist</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_hashs</span>(<span class="params">self, value</span>):</span><br><span class="line">        hashs = <span class="built_in">list</span>()</span><br><span class="line">        <span class="keyword">for</span> seed <span class="keyword">in</span> self.seeds:</span><br><span class="line">            <span class="built_in">hash</span> = mmh3.<span class="built_in">hash</span>(value, seed)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hash</span> &gt;= <span class="number">0</span>:</span><br><span class="line">                hashs.append(<span class="built_in">hash</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                hashs.append(self.N - <span class="built_in">hash</span>)</span><br><span class="line">        <span class="keyword">return</span> hashs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Downloader</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start_url_list</span>):</span><br><span class="line">        self.headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">        self.r = redis.StrictRedis(host=<span class="string">&#x27;127.0.0.1&#x27;</span>, port=<span class="number">6379</span>, db=<span class="number">2</span>, decode_responses=<span class="literal">True</span>)</span><br><span class="line">        self.bf = BloomFilter(conn=self.r)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> start_url_list:</span><br><span class="line">            self.r.lpush(<span class="string">&#x27;url_list&#x27;</span>, item)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据url请求网址并返回html</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_html</span>(<span class="params">self, url, header=<span class="literal">None</span></span>):</span><br><span class="line">        sem = asyncio.Semaphore(<span class="number">100</span>)  <span class="comment"># 并发数量限制</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">with</span> sem:</span><br><span class="line">                <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession(headers=header, cookies=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> session:</span><br><span class="line">                    <span class="keyword">async</span> <span class="keyword">with</span> session.get(url, proxy=<span class="string">&#x27;http://127.0.0.1:7890&#x27;</span>) <span class="keyword">as</span> resp:</span><br><span class="line">                        <span class="keyword">if</span> resp.status <span class="keyword">in</span> [<span class="number">200</span>, <span class="number">201</span>]:</span><br><span class="line">                            data = <span class="keyword">await</span> resp.text()</span><br><span class="line">                            <span class="keyword">return</span> data</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取网页中的pdf链接</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getPDF</span>(<span class="params">self, content, base_url</span>):</span><br><span class="line">        pdf = <span class="string">r&quot;href.*\.pdf\&quot;&quot;</span></span><br><span class="line">        pdflist = re.findall(pdf, content)</span><br><span class="line">        fianl_url_list = []</span><br><span class="line">        <span class="comment"># 进行相对路径--&gt; 绝对路径转换</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> pdflist:</span><br><span class="line">            item_url = item[<span class="number">6</span>:-<span class="number">1</span>]</span><br><span class="line">            new_full_url = parse.urljoin(base_url, item_url)</span><br><span class="line">            fianl_url_list.append(new_full_url)</span><br><span class="line">        <span class="keyword">return</span> fianl_url_list</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据pdf链接下载</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">downloadPDF</span>(<span class="params">self, item</span>):</span><br><span class="line">        filename = os.path.basename(parse.unquote(item))</span><br><span class="line">        cop = re.<span class="built_in">compile</span>(<span class="string">&quot;[^\u4e00-\u9fa5^a-z^A-Z^0-9^\.]&quot;</span>)  <span class="comment"># 匹配不是中文、大小写、数字的其他字符</span></span><br><span class="line">        filename = cop.sub(<span class="string">&#x27;&#x27;</span>, filename)  <span class="comment"># 将string1中匹配到的字符替换成空字符</span></span><br><span class="line">        salt = <span class="string">&#x27;&#x27;</span>.join([<span class="string">&quot;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(random.randint(<span class="number">0</span>, <span class="number">9</span>)) <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">5</span>)])</span><br><span class="line">        filename = salt + filename</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            responsepdf = requests.get(item, proxies=proxies)</span><br><span class="line">            <span class="keyword">if</span> responsepdf.status_code == <span class="number">200</span>:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">r&quot;E:/pdf/%s&quot;</span> % filename, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> code:</span><br><span class="line">                    code.write(responsepdf.content)</span><br><span class="line">                    time.sleep(<span class="number">1</span>)  <span class="comment"># 防止访问速度过快，可以灵活的调整时间</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取网页中的链接</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getAllhref</span>(<span class="params">self, html, base_url</span>):</span><br><span class="line">        <span class="comment"># 使用BeautifulSoup函数解析传入的html</span></span><br><span class="line">        soup = bs(html, features=<span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">        allnode_of_a = soup.find_all(<span class="string">&quot;a&quot;</span>)</span><br><span class="line">        result = [_.get(<span class="string">&quot;href&quot;</span>).strip() <span class="keyword">for</span> _ <span class="keyword">in</span> allnode_of_a <span class="keyword">if</span> _ <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> _.get(<span class="string">&quot;href&quot;</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>]</span><br><span class="line">        <span class="comment"># 有些是相对路径，需要转换为绝对路径</span></span><br><span class="line">        filterResult = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> result:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(item) &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> item.startswith(<span class="string">&quot;http&quot;</span>):</span><br><span class="line">                    filterResult.append(item)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    new_full_url = parse.urljoin(base_url, item)</span><br><span class="line">                    filterResult.append(new_full_url)</span><br><span class="line">        <span class="keyword">return</span> filterResult</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 传入一个 redis list，开始从里面取出一个url并请求数据</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">start_spider</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            cur_url = self.r.rpop(<span class="string">&#x27;url_list&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> cur_url <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> self.bf.is_exist(cur_url):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            response = <span class="keyword">await</span> self.get_html(url=cur_url, header=self.headers)</span><br><span class="line">            <span class="comment"># 将访问过的url加入到bloom filter</span></span><br><span class="line">            self.bf.add(cur_url)</span><br><span class="line">            <span class="keyword">if</span> response <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                pdflist = self.getPDF(response, cur_url)</span><br><span class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> pdflist:</span><br><span class="line">                    self.downloadPDF(item)</span><br><span class="line">                nextList = self.getAllhref(response, cur_url)</span><br><span class="line">                <span class="keyword">for</span> url <span class="keyword">in</span> nextList:</span><br><span class="line">                    self.r.lpush(<span class="string">&#x27;url_list&#x27;</span>, url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    start_url_list = [<span class="string">&quot;https://github.com/Kensuke-Hinata/statistic/tree/master/os/books&quot;</span>]</span><br><span class="line">    downloader = Downloader(start_url_list)</span><br><span class="line">    <span class="keyword">await</span> downloader.start_spider()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    loop = asyncio.get_event_loop()</span><br><span class="line">    loop.run_until_complete(main())</span><br></pre></td></tr></table></figure>



      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/01/02/downloader/" data-id="cloqxfco9000g0wu56l787ff0" data-title="downloader" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-python计算机视觉" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/12/29/python%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" class="article-date">
  <time class="dt-published" datetime="2022-12-29T12:57:59.000Z" itemprop="datePublished">2022-12-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/12/29/python%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">python计算机视觉</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>python计算机视觉涉及到图形图像，线性代数，概率论，python语言等知识。</p>
<h2 id="形态学图像处理"><a href="#形态学图像处理" class="headerlink" title="形态学图像处理"></a>形态学图像处理</h2><p>形态学图像处理有两个关键概念：结构元与形态学操作，基础的形态学操作有腐蚀，膨胀，衍生的形态学操作有开运算，闭运算，顶帽运算，底帽运算，形态学梯度（获取轮廓），常见的应用有边界提取，孔洞填充，计算连通分量，计算凸包，骨架，水平垂直线提取，灰度图的阴影矫正，灰度图图像平滑，纹理分割等。有关形态学的教材一般从集合的形式阐述各种形态学操作，个人认为直接上手操作更直观，参考博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/youcans/category_11459626.html">https://blog.csdn.net/youcans/category_11459626.html</a><br>结构元的构建可以使用以下两种方式，两者等价</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kSize = (<span class="number">3</span>, <span class="number">3</span>)  <span class="comment"># 卷积核的尺寸</span></span><br><span class="line">kernel = np.ones(kSize, dtype=np.uint8)  <span class="comment"># 生成盒式卷积核</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 等价于</span></span><br><span class="line">element = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<p>基本的形态学操作记录如下，方便以后查阅</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 腐蚀</span></span><br><span class="line">imgErode = cv2.erode(imgBin, kernel=kernel)  <span class="comment"># 图像腐蚀</span></span><br><span class="line"><span class="comment"># 膨胀</span></span><br><span class="line">imgDilate = cv2.dilate(imgBin, kernel=kernel)  <span class="comment"># 图像膨胀</span></span><br><span class="line"><span class="comment"># 开运算</span></span><br><span class="line">imgOpen = cv2.morphologyEx(imgGray, cv2.MORPH_OPEN, kernel)</span><br><span class="line"><span class="comment"># 闭运算</span></span><br><span class="line">imgClose = cv2.morphologyEx(imgBin, cv2.MORPH_CLOSE, kernel)</span><br><span class="line"><span class="comment"># 顶帽运算</span></span><br><span class="line">imgThat = cv2.morphologyEx(imgBin, cv2.MORPH_TOPHAT, kernel)  <span class="comment"># 顶帽运算</span></span><br><span class="line"><span class="comment"># 底帽运算</span></span><br><span class="line">imgBhat = cv2.morphologyEx(imgBin, cv2.MORPH_BLACKHAT, kernel)  <span class="comment"># 底帽运算</span></span><br><span class="line"><span class="comment"># 形态学梯度</span></span><br><span class="line">imgGrad = cv2.morphologyEx(imgBin, cv2.MORPH_GRADIENT, kernel)  <span class="comment"># 形态学梯度</span></span><br><span class="line"><span class="comment"># 击中与不击中操作在实现上相对复杂一些，涉及到两个结构元</span></span><br><span class="line">kernB1 = np.array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],[<span class="number">0</span>, -<span class="number">1</span>, <span class="number">1</span>],[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]], dtype=np.int32)  <span class="comment"># B1</span></span><br><span class="line">kernB2 = np.array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],[<span class="number">1</span>, -<span class="number">1</span>, <span class="number">0</span>],[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]], dtype=np.int32)  <span class="comment"># B2</span></span><br><span class="line">imgH1 = cv2.morphologyEx(img, cv2.MORPH_HITMISS, kernB1)</span><br><span class="line">imgH2 = cv2.morphologyEx(img, cv2.MORPH_HITMISS, kernB2)</span><br><span class="line">imgHMT = cv2.add(imgH1, imgH2)  <span class="comment"># 击中击不中</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>




      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/12/29/python%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" data-id="cloqxfcns00050wu5d723872l" data-title="python计算机视觉" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-video-captioning-baseline" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/12/21/video-captioning-baseline/" class="article-date">
  <time class="dt-published" datetime="2022-12-21T13:38:58.000Z" itemprop="datePublished">2022-12-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/12/21/video-captioning-baseline/">video_captioning_baseline</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>本文讲解video captioning中一个简单但效果不错的baseline，GitHub仓库为：<a target="_blank" rel="noopener" href="https://github.com/ramakanth-pasunuru/video_captioning_rl">https://github.com/ramakanth-pasunuru/video_captioning_rl</a><br>该baseline基于pytorch框架，主要包括数据预处理，数据加载，网络搭建，模型优化几个模块，虽然代码用的是LSTM网络，但换成现在主流的Transformer网络整体pipeline是相同的</p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>该阶段包括视频特征的提取及词库的创建，其中视频特征一般提取两种特征，每帧的appearance feature及motion feature，当然也可以提取每帧的object feature，该baseline使用预训练的ResNet-152提取appearance feature，ResNeXt-101提取motion feature，如果有需要，你可以自己使用检测网络提取object feature，特征下载参见GitHub仓库。而对于文本的处理为统计预料库中单词出现的次数并进行筛选，比如过滤掉频次小于2的单词，添加 start, end, token 标签分别代表句子的开头，结尾及未知词。<br>特别需要形成的一个意识是一个单词对应一个数字, 比如 单词 love 对应 数字5，词库是100，则单词编码是0-99，最后生成的是一个100维矢量，希望经过softmax后第6维(因为从0开始计数)的数值最大。具体查看one-hot相关知识。<br>以下为构建单词与数字对应关系的代码结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vocab</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,vocab_file,max_size</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Creates a vocab of up to max_size words, reading from the vocab_file. If max_size is 0, reads the entire vocab file.</span></span><br><span class="line"><span class="string">            Args:</span></span><br><span class="line"><span class="string">                vocab_file: path to the vocab file, which is assumed to contain &quot;&lt;word&gt; &lt;frequency&gt;&quot; on each line, sorted with most frequent word first. </span></span><br><span class="line"><span class="string">                            This code doesn&#x27;t actually use the frequencies, though.</span></span><br><span class="line"><span class="string">                max_size: integer. The maximum size of the resulting Vocabulary.</span></span><br><span class="line"><span class="string">                </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self._word_to_id = &#123;&#125;</span><br><span class="line">        self._id_to_word = &#123;&#125;</span><br><span class="line">        self._count = <span class="number">0</span> <span class="comment"># keeps track of total number of words in the Vocab</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># [PAD], [START], [STOP] and [UNK] get the ids 0,1,2,3.</span></span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> [PAD_TOKEN, START_DECODING, STOP_DECODING, UNKNOWN_TOKEN]:</span><br><span class="line">            self._word_to_id[w] = self._count</span><br><span class="line">            self._id_to_word[self._count] = w</span><br><span class="line">            self._count += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 读取词库，构建单词与数字对应关系</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">word2id</span>(<span class="params">self, word</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Returns the id (integer) of a word (string). Returns [UNK] id if word is OOV.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self._word_to_id:</span><br><span class="line">            <span class="keyword">return</span> self._word_to_id[UNKNOWN_TOKEN]</span><br><span class="line">        <span class="keyword">return</span> self._word_to_id[word]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">id2word</span>(<span class="params">self, word_id</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Returns the word (string) corresponding to an id (integer).&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> word_id <span class="keyword">not</span> <span class="keyword">in</span> self._id_to_word:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Id not found in vocab: %d&#x27;</span> % word_id)</span><br><span class="line">        <span class="keyword">return</span> self._id_to_word[word_id]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><p>考虑一个业务场景，怎样把硬盘中的超大文件加载到内存? 这时就需要一个函数能够读取文件的一部分到内存，同时记录读取到哪个地方了，而生成器恰好实现了这样的功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">file_reader</span>(<span class="params">fp, block_size=<span class="number">1024</span> * <span class="number">8</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成器函数：分块读取文件内容</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = fp.read(block_size)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> chunk:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">yield</span> chunk</span><br></pre></td></tr></table></figure>
<p>而在网络结构的训练中，数据是以批 batch 的形式喂到网络结构中的，因此在数据加载部分涉及到迭代器及生成器相关知识。<br>常用的数据加载相关代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先定义自己的 MyDataset类，继承自 Dataset</span></span><br><span class="line"><span class="comment"># 在自己的Dataset类中一般需要实现 初始化函数 __init__, 获取元素 __getitem__ 及返回整个数据长度 __len__</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将实例化的Dataset对象输入到Dataloader中便可以以生成器的方式迭代获取数据</span></span><br><span class="line">dataset = MyDataset()</span><br><span class="line">dataloader = Dataloader(dataset, ...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代获取 batch 数据 训练网络</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">   <span class="comment"># training...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 等价与</span></span><br><span class="line">iterr = <span class="built_in">iter</span>(dataloader)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">next</span>(iterr)</span><br><span class="line">    <span class="comment"># training...</span></span><br><span class="line">  <span class="keyword">except</span> StopIteration:</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>Dataloader的源码相对复杂，我觉得也没有研究的必要，了解其过程就行，这里关于怎样从Dataloader加载数据的步骤引自  <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30934236">https://zhuanlan.zhihu.com/p/30934236</a></p>
<ol>
<li>调用了dataloader 的__iter__() 方法, 产生了一个DataLoaderIter</li>
<li>反复调用DataLoaderIter 的__next__()来得到batch, 具体操作就是, 多次调用dataset的__getitem__()方法 (如果num_worker&gt;0就多线程调用), 然后用collate_fn来把它们打包成batch. 中间还会涉及到shuffle , 以及sample 的方法等, 这里就不多说了.</li>
<li>当数据读完后, <strong>next</strong>()抛出一个StopIteration异常, for循环结束, dataloader 失效.</li>
</ol>
<p>dataloader也可以自己写，比如 MSRVTTBatcher 的 get_batcher 通过关键字yield构建了生成器，就可以next的方式迭代获取数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MSRVTTBatcher</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,hps,mode,vocab</span>):</span><br><span class="line">        <span class="comment"># 初始化一些词库路径，视觉特征路径等信息</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_process_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;this module extracts data from videos and caption files and creates batches&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># load json data which contains all the information</span></span><br><span class="line">        <span class="comment"># 用于构建 video 与 caption 的关联字典</span></span><br><span class="line">        <span class="keyword">if</span> self._mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">            np.random.shuffle(data)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            data,_ = <span class="built_in">zip</span>(*data) <span class="comment"># consider only video ids for evaluation</span></span><br><span class="line">            data = <span class="built_in">sorted</span>(<span class="built_in">set</span>(data),key=data.index)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> data,data_dict</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sort_based_on_caption_lengths</span>(<span class="params">self, video_batch, video_len_batch, video_id, caption_batch, caption_len_batch, original_caption:</span></span><br><span class="line"><span class="params">        <span class="comment"># 根据captioning的长度排序，主要是为了 后续 nn.utils.rnn.pack_padded_sequence 的需要</span></span></span><br><span class="line"><span class="params">    </span></span><br><span class="line"><span class="params">    <span class="keyword">def</span> get_batcher(<span class="params">self</span>):</span></span><br><span class="line"><span class="params">        <span class="string">&quot;&quot;&quot;</span></span></span><br><span class="line"><span class="string"><span class="params">        This module process data and creates batches for train/val/test </span></span></span><br><span class="line"><span class="string"><span class="params">        Also acts as generator</span></span></span><br><span class="line"><span class="string"><span class="params">        &quot;&quot;&quot;</span></span></span><br><span class="line"><span class="params">        <span class="comment"># 构建生成器，以 批 迭代的方式获取数据</span></span></span><br><span class="line"><span class="params">        <span class="keyword">yield</span> batch</span></span><br></pre></td></tr></table></figure>

<h2 id="网络搭建"><a href="#网络搭建" class="headerlink" title="网络搭建"></a>网络搭建</h2><p>神经网络说到底还是矩阵运算，论文中的每个公式与相应的代码一一对应。一般的网络结构定义及调用如下，值得注意的地方是调用网络的时候似乎没有显性调用forward函数，这是因为在执行model(data)的时候，实际执行的是model.<strong>call</strong>(data), 而其继承自nn.Module，所以会调用父类的魔术函数__call__, 在该函数中会调用forward函数及很多其他钩子函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网络结构的定义，继承自 nn.Module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="comment"># 初始化网络模块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 搭建网络结构</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        <span class="keyword">return</span> F.relu(self.conv2(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化网络</span></span><br><span class="line">model = Model()</span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line"><span class="comment"># 实际执行的是model.__call__(data)</span></span><br><span class="line">model(data)</span><br></pre></td></tr></table></figure>
<p>而对于captioning任务，理论部分提到过一般分为encoder和decoder，所以在代码上也是对应的，一般会使用一个类来总管encoder和decoder。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2seqAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2seqAttention, self).__init__()</span><br><span class="line">        self.args = args</span><br><span class="line">        self.enable_cuda = args.cuda</span><br><span class="line">        self.vid_dim = args.vid_dim</span><br><span class="line">        self.embed_size = args.embed</span><br><span class="line">        self.hidden_dim = args.hid</span><br><span class="line">        self.vocab_size = args.max_vocab_size</span><br><span class="line">        self.num_layers = args.num_layers</span><br><span class="line">        self.birnn = args.birnn</span><br><span class="line">        self.encoder = EncoderFrames(self.args)</span><br><span class="line">        self.decoder = DecoderRNN(self.args)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, frames, flengths, captions, lengths</span>):</span><br><span class="line">        video_features = self.encoder(frames, flengths)</span><br><span class="line">        outputs = self.decoder(video_features, flengths, captions, lengths)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>
<p>值得特别注意的是该代码在encoder部分使用了pack_padded_sequence，算是一个减小padding噪音的trick</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Based on tutorials/08 - Language Model</span></span><br><span class="line"><span class="comment"># RNN Based Language Model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderFrames</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args</span>):</span><br><span class="line">        <span class="built_in">super</span>(EncoderFrames, self).__init__()</span><br><span class="line">        <span class="comment"># self.use_abs = use_abs</span></span><br><span class="line">        self.vid_dim = args.vid_dim</span><br><span class="line">        self.embed_size = args.embed</span><br><span class="line">        self.hidden_dim = args.hid</span><br><span class="line">        self.enable_cuda = args.cuda</span><br><span class="line">        self.num_layers = args.num_layers</span><br><span class="line">        self.args = args</span><br><span class="line">        <span class="keyword">if</span> args.birnn:</span><br><span class="line">            self.birnn = <span class="number">2</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.birnn = <span class="number">1</span></span><br><span class="line">        <span class="comment"># projection layer</span></span><br><span class="line">        self.linear = nn.Linear(self.vid_dim, self.embed_size, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># video embedding</span></span><br><span class="line">        self.rnn = nn.LSTM(self.embed_size, self.hidden_dim, self.num_layers, batch_first=<span class="literal">True</span>, bidirectional=self.args.birnn, dropout=args.dropout)</span><br><span class="line">        self.dropout = nn.Dropout(args.dropout)</span><br><span class="line">        self.init_weights()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">self</span>):</span><br><span class="line">        self.rnn.weight_hh_l0.data.uniform_(-<span class="number">0.08</span>, <span class="number">0.08</span>)</span><br><span class="line">        self.rnn.weight_ih_l0.data.uniform_(-<span class="number">0.08</span>, <span class="number">0.08</span>)</span><br><span class="line">        self.rnn.bias_ih_l0.data.fill_(<span class="number">0</span>)</span><br><span class="line">        self.rnn.bias_hh_l0.data.fill_(<span class="number">0</span>)</span><br><span class="line">        self.linear.weight.data.uniform_(-<span class="number">0.08</span>, <span class="number">0.08</span>)</span><br><span class="line">        <span class="comment">#self.linear.bias.data.fill_(0)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self, batch_size</span>):</span><br><span class="line">        <span class="keyword">if</span> self.birnn:</span><br><span class="line">            <span class="keyword">return</span> (Variable(torch.zeros(self.birnn*self.num_layers, batch_size, self.hidden_dim)),</span><br><span class="line">                    Variable(torch.zeros(self.birnn*self.num_layers, batch_size, self.hidden_dim)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, frames, flengths</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Handles variable size frames</span></span><br><span class="line"><span class="string">           frame_embed: video features</span></span><br><span class="line"><span class="string">           flengths: frame lengths</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        batch_size = flengths.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="comment">#frames = self.linear(frames)</span></span><br><span class="line">        <span class="comment">#frames = self.dropout(frames) # adding dropout layer</span></span><br><span class="line">        self.init_rnn = self.init_hidden(batch_size)</span><br><span class="line">        <span class="keyword">if</span> self.enable_cuda:</span><br><span class="line">            self.init_rnn = self.init_rnn[<span class="number">0</span>].cuda(), self.init_rnn[<span class="number">1</span>].cuda()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_size &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># Sort by length (keep idx)</span></span><br><span class="line">            flengths, idx_sort = np.sort(flengths)[::-<span class="number">1</span>], np.argsort(-flengths)</span><br><span class="line">            <span class="keyword">if</span> self.enable_cuda:</span><br><span class="line">                frames = frames.index_select(<span class="number">0</span>, Variable(torch.cuda.LongTensor(idx_sort)))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                frames = frames.index_select(<span class="number">0</span>, Variable(torch.LongTensor(idx_sort)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        frames = self.linear(frames)</span><br><span class="line">        <span class="comment"># 值得特别注意，一个小trick</span></span><br><span class="line">        frame_packed = nn.utils.rnn.pack_padded_sequence(frames, flengths, batch_first=<span class="literal">True</span>)</span><br><span class="line">        outputs, (ht, ct) = self.rnn(frame_packed, self.init_rnn)</span><br><span class="line">        outputs,_ = pad_packed_sequence(outputs,batch_first=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_size &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># Un-sort by length</span></span><br><span class="line">            idx_unsort = np.argsort(idx_sort)</span><br><span class="line">            <span class="keyword">if</span> self.enable_cuda:</span><br><span class="line">                outputs = outputs.index_select(<span class="number">0</span>, Variable(torch.cuda.LongTensor(idx_unsort)))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                outputs = outputs.index_select(<span class="number">0</span>, Variable(torch.LongTensor(idx_unsort)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print &#x27;Encoder Outputs:&#x27;,outputs.size()</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>

<p><strong>特别提醒一下该词库有关beam search及强化学习的代码也是非常清晰，对于原理学习及后续改进都十分有利</strong></p>
<h2 id="模型优化"><a href="#模型优化" class="headerlink" title="模型优化"></a>模型优化</h2><p>这个地方代码差不多，注意训练的时候调用model.train(),测试的时候调用model.eval(), 还有注意交叉熵损失函数的输入就行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">self</span>):</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    model = self.model</span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    batcher = self.train_data.get_batcher()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,self.train_data.num_steps): </span><br><span class="line">        batch = <span class="built_in">next</span>(batcher)</span><br><span class="line">        <span class="comment"># 获取数据</span></span><br><span class="line">        video_features = batch.get(<span class="string">&#x27;video_batch&#x27;</span>)</span><br><span class="line">        flengths = batch.get(<span class="string">&#x27;video_len_batch&#x27;</span>)</span><br><span class="line">        captions = batch.get(<span class="string">&#x27;caption_batch&#x27;</span>)</span><br><span class="line">        clengths = batch.get(<span class="string">&#x27;caption_len_batch&#x27;</span>)</span><br><span class="line">        video_features = to_var(self.args, video_features)</span><br><span class="line">        captions = to_var(self.args, captions)</span><br><span class="line">        <span class="comment"># 求损失函数</span></span><br><span class="line">        outputs = self.model(video_features, flengths, captions, clengths)</span><br><span class="line">        targets = pack_padded_sequence(captions, clengths, batch_first=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">        loss = self.ce(outputs, targets)</span><br><span class="line">           </span><br><span class="line">        <span class="comment"># update</span></span><br><span class="line">        self.optim.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        t.nn.utils.clip_grad_norm(</span><br><span class="line">                model.parameters(), self.args.grad_clip)</span><br><span class="line">        self.optim.step()</span><br><span class="line"></span><br><span class="line">        total_loss += loss.data</span><br><span class="line">        pbar.set_description(<span class="string">f&quot;train_model| loss: <span class="subst">&#123;loss.data[<span class="number">0</span>]:<span class="number">5.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        step += <span class="number">1</span></span><br><span class="line">        self.step += <span class="number">1</span></span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/12/21/video-captioning-baseline/" data-id="cloqxfco2000b0wu53688egvl" data-title="video_captioning_baseline" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-video-caption" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/12/10/video-caption/" class="article-date">
  <time class="dt-published" datetime="2022-12-10T09:42:07.000Z" itemprop="datePublished">2022-12-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/12/10/video-caption/">video captioning</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>video captioning 是一项跨模态任务，输入视频，输出自然语言来描述视频内容。video captioning的pipeline如图所示。首先使用预训练的模型(如resnet)提取视觉特征，然后通过编码器对视觉特征进一步融合，最后使用解码器生成句子。<br><img src="/../images/video_captioning_pipeline.png"><br>以下结合论文阐述video captioning上一些重要的工作，image captioning 与 video captioning 有着高度相似，因此以下会参杂着一些image captioning的文章。</p>
<h2 id="Show-and-Tell-A-Neural-Image-Caption-Generator-2015"><a href="#Show-and-Tell-A-Neural-Image-Caption-Generator-2015" class="headerlink" title="Show and Tell: A Neural Image Caption Generator[2015]"></a>Show and Tell: A Neural Image Caption Generator[2015]</h2><p>image captioning方向的早期工作，使用预训练的VGG模型提取图像特征，输入到LSTM中生成句子<br><img src="/../images/show_and_tell.png"></p>
<h2 id="Sequence-to-Sequence-–-Video-to-Text-2015"><a href="#Sequence-to-Sequence-–-Video-to-Text-2015" class="headerlink" title="Sequence to Sequence – Video to Text[2015]"></a>Sequence to Sequence – Video to Text[2015]</h2><p>video captioning方向的早期工作，同样是使用预训练模型提取图像特征后输入到LSTM中生成句子，与 image captioning 不同的是使用了双层LSTM来融合不同视频帧的特征<br><img src="/../images/sequence_to_sequence.png"></p>
<h2 id="Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention-2016"><a href="#Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention-2016" class="headerlink" title="Show, Attend and Tell: Neural Image Caption Generation with Visual Attention [2016]"></a>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention [2016]</h2><p>将注意力机制引入到image captioning，其出发点是生成每个词的时候提取最相关的视觉特征。注意力机制是一个重要的研究点，结合任务产生了各种不同的注意力机制。<br><img src="/../images/show_attend_tell_1.png"><br><img src="/../images/show_attend_tell_2.png"></p>
<h2 id="Knowing-When-to-Look-Adaptive-Attention-via-A-Visual-Sentinel-for-Image-Captioning-2017"><a href="#Knowing-When-to-Look-Adaptive-Attention-via-A-Visual-Sentinel-for-Image-Captioning-2017" class="headerlink" title="Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning [2017]"></a>Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning [2017]</h2><p>注意力机制的改进之一，出发点在于句子中的连接词是与视觉特征无关的，更多取决于句子中的语法结构，其动机图如下<br><img src="/../images/know_when_to_look.png"><br>其实现方式也值得借鉴，直接增加一个表示句子内容的特征矢量<br><img src="/../images/knwo_when_to_look_framework.png"></p>
<h2 id="Attention-on-Attention-for-Image-Captioning-2019"><a href="#Attention-on-Attention-for-Image-Captioning-2019" class="headerlink" title="Attention on Attention for Image Captioning [2019]"></a>Attention on Attention for Image Captioning [2019]</h2><p>同样是对注意力机制的改进，并且效果还行，被后续挺多文章引入到框架中<br><img src="/../images/AOA.png"><br>关于动机，直接引用原文的措辞：to measure the relevance between the attention result and the query<br>另外还有很多其他关于注意力机制的改进，如X-Linear Attention Networks for Image Captioning [2020]，Motion Guided Spatial Attention for Video Captioning [2019]，More Grounded Image Captioning by Distilling Image-Text Matching Model [2020]等，本文不作一一阐述。</p>
<h2 id="Reconstruction-Network-for-Video-Captioning-2018"><a href="#Reconstruction-Network-for-Video-Captioning-2018" class="headerlink" title="Reconstruction Network for Video Captioning [2018]"></a>Reconstruction Network for Video Captioning [2018]</h2><p>在结构上面，该文在编码器解码器后添加了重构器形成了闭环，即通过生成的文字特征重构视觉特征。<br><img src="/../images/reconstruction_network.png"></p>
<h2 id="Meshed-Memory-Transformer-for-Image-Captioning-2020"><a href="#Meshed-Memory-Transformer-for-Image-Captioning-2020" class="headerlink" title="Meshed-Memory Transformer for Image Captioning [2020]"></a>Meshed-Memory Transformer for Image Captioning [2020]</h2><p>随着transformer在自然语言方向的应用，近年transformer也成为了image captioning和video captioning的主流框架。<br><img src="/../images/meshed_transformer.png"></p>
<h2 id="Unified-Vision-Language-Pre-Training-for-Image-Captioning-and-VQA-2019"><a href="#Unified-Vision-Language-Pre-Training-for-Image-Captioning-and-VQA-2019" class="headerlink" title="Unified Vision-Language Pre-Training for Image Captioning and VQA [2019]"></a>Unified Vision-Language Pre-Training for Image Captioning and VQA [2019]</h2><p>统一框架也是研究热点，如将captioning和VQA融合到一个框架中，关于统一框架建议先看 Unified Language Model Pre-training for Natural Language Understanding and Generation [2019]<br><img src="/../images/unified_framework.png"></p>
<h2 id="Towards-Unsupervised-Image-Captioning-with-Shared-Multimodal-Embeddings-2019"><a href="#Towards-Unsupervised-Image-Captioning-with-Shared-Multimodal-Embeddings-2019" class="headerlink" title="Towards Unsupervised Image Captioning with Shared Multimodal Embeddings [2019]"></a>Towards Unsupervised Image Captioning with Shared Multimodal Embeddings [2019]</h2><p>除了使用监督学习的方式，无监督学习框架在captioning也有应用，可以参考 unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks[2017]<br><img src="/../images/unsupervised_framework.png"></p>
<h2 id="Bottom-Up-and-Top-Down-Attention-for-Image-Captioning-and-Visual-Question-Answering-2018"><a href="#Bottom-Up-and-Top-Down-Attention-for-Image-Captioning-and-Visual-Question-Answering-2018" class="headerlink" title="Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering [2018]"></a>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering [2018]</h2><p>captioning作为一个图像到文本的跨模态任务，更有效的图像提取特征方式能够提高其指标，该文使用了目标检测网络提取图像特征。<br><img src="/../images/bottom_up_top_down.png"></p>
<h2 id="Aligning-Linguistic-Words-and-Visual-Semantic-Units-for-Image-Captioning-2019"><a href="#Aligning-Linguistic-Words-and-Visual-Semantic-Units-for-Image-Captioning-2019" class="headerlink" title="Aligning Linguistic Words and Visual Semantic Units for Image Captioning [2019]"></a>Aligning Linguistic Words and Visual Semantic Units for Image Captioning [2019]</h2><p>该文在视觉特征提取上更进一步，除了提取object feature，还提取了object之间的关系特征，关于这个关系特征如何提取参考：Neural Motifs: Scene Graph Parsing with Global Context [2017]<br><img src="/../images/aligning_linguistic_words_visual.png"><br>最后其网络框架如图<br><img src="/../images/aligning_linguistic_word_visual_framework.png"></p>
<h2 id="Improving-Image-Captioning-with-Better-Use-of-Captions-2020"><a href="#Improving-Image-Captioning-with-Better-Use-of-Captions-2020" class="headerlink" title="Improving Image Captioning with Better Use of Captions [2020]"></a>Improving Image Captioning with Better Use of Captions [2020]</h2><p>在视觉object关系特征提取上，上文用的是Motifs以监督的方式生成的，该文提出从captioning端也构建一个场景图来指导视觉场景图的生成<br><img src="/../images/better_use_caption.png"><br>视觉关系应用到基础的检测网络框架也有相关尝试，参见：Visual Commonsense R-CNN [2020]</p>
<h2 id="Object-Relational-Graph-with-Teacher-Recommended-Learning-for-Video-Captioning-2020"><a href="#Object-Relational-Graph-with-Teacher-Recommended-Learning-for-Video-Captioning-2020" class="headerlink" title="Object Relational Graph with Teacher-Recommended Learning for Video Captioning [2020]"></a>Object Relational Graph with Teacher-Recommended Learning for Video Captioning [2020]</h2><p>在image captioning方向可以使用有监督的方式来生成场景图信息，从而利用其中的关系特征，但是在video captioning就难以生成相应的时间和空间关系特征了，该文直接将其包含在网络结构中让其自动学习object之间的关系特征，非常巧妙<br><img src="/../images/object_relation_graph.png"></p>
<h2 id="M3-Multimodal-Memory-Modelling-for-Video-Captioning-2018"><a href="#M3-Multimodal-Memory-Modelling-for-Video-Captioning-2018" class="headerlink" title="M3: Multimodal Memory Modelling for Video Captioning [2018]"></a>M3: Multimodal Memory Modelling for Video Captioning [2018]</h2><p>captioning任务作为一个文本生成任务，很多machine translation任务存在的问题及解决方法对captioning任务同样有效，如使用记忆网络来解决长时序依赖问题，对应在machine translation的文章为Neural Turing Machines [2014]<br><img src="/../images/m3.png"></p>
<h2 id="Controllable-Video-Captioning-with-POS-Sequence-Guidance-Based-on-Gated-Fusion-Network-2019"><a href="#Controllable-Video-Captioning-with-POS-Sequence-Guidance-Based-on-Gated-Fusion-Network-2019" class="headerlink" title="Controllable Video Captioning with POS Sequence Guidance Based on Gated Fusion Network [2019]"></a>Controllable Video Captioning with POS Sequence Guidance Based on Gated Fusion Network [2019]</h2><p>或者是使用POS信息来从语法上约束生成的句子<br><img src="/../images/pos.png"></p>
<h2 id="Object-Relational-Graph-with-Teacher-Recommended-Learning-for-Video-Captioning-2020-1"><a href="#Object-Relational-Graph-with-Teacher-Recommended-Learning-for-Video-Captioning-2020-1" class="headerlink" title="Object Relational Graph with Teacher-Recommended Learning for Video Captioning [2020]"></a>Object Relational Graph with Teacher-Recommended Learning for Video Captioning [2020]</h2><p>针对语料库的长尾效应，使用预训练模型对其进行修正<br><img src="/../images/org.png"></p>
<h2 id="Semantic-Compositional-Networks-for-Visual-Captioning-2017"><a href="#Semantic-Compositional-Networks-for-Visual-Captioning-2017" class="headerlink" title="Semantic Compositional Networks for Visual Captioning [2017]"></a>Semantic Compositional Networks for Visual Captioning [2017]</h2><p>从图像信息中提取出属性信息，指导句子的生成<br><img src="/../images/scn.png"></p>
<h2 id="Bridging-byWord-Image-Grounded-Vocabulary-Construction-for-Visual-Captioning-2019"><a href="#Bridging-byWord-Image-Grounded-Vocabulary-Construction-for-Visual-Captioning-2019" class="headerlink" title="Bridging byWord: Image-Grounded Vocabulary Construction for Visual Captioning [2019]"></a>Bridging byWord: Image-Grounded Vocabulary Construction for Visual Captioning [2019]</h2><p>这篇文章和从图像提取属性信息辅助句子生成类似，不过该文是通过图像来缩小生成句子的词空间，很巧妙。<br><img src="/../images/bridging_by_word.png"></p>
<h2 id="Bridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translation-2019"><a href="#Bridging-the-Gap-between-Training-and-Inference-for-Neural-Machine-Translation-2019" class="headerlink" title="Bridging the Gap between Training and Inference for Neural Machine Translation [2019]"></a>Bridging the Gap between Training and Inference for Neural Machine Translation [2019]</h2><p>既然是序列生成任务自然存在exposure bias问题，该文在训练与测试的差异及训练难度上取了一个折中(关于训练阶段为什么不直接使用上个一个时间步生成的单词输入到当前时间步，因为这样很难训练好，误差积累太大，难收敛)<br><img src="/../images/bridging_gap.png"></p>
<h2 id="Self-critical-Sequence-Training-for-Image-Captioning-2017"><a href="#Self-critical-Sequence-Training-for-Image-Captioning-2017" class="headerlink" title="Self-critical Sequence Training for Image Captioning [2017]"></a>Self-critical Sequence Training for Image Captioning [2017]</h2><p>其实解决exposure bias问题更有效的方式是使用强化学习，当然一般会先用交叉熵训练好模型，然后交叉熵+强化学习的方式继续训练模型<br><img src="/../images/scs.png"><br><img src="/../images/scs_example.png"></p>
<h2 id="Non-Autoregressive-Coarse-to-Fine-Video-Captioning-2021"><a href="#Non-Autoregressive-Coarse-to-Fine-Video-Captioning-2021" class="headerlink" title="Non-Autoregressive Coarse-to-Fine Video Captioning [2021]"></a>Non-Autoregressive Coarse-to-Fine Video Captioning [2021]</h2><p>另外也有非自回归这种方式用于生成句子，这种方式自然不存在exposure bias问题，而且生成速度更快，但由于没有直接建模生成单词之间的依赖关系，一般效果不如自回归生成模型，更多需要参考自然语言方向对其的改进。<br><img src="/../images/na.png"></p>
<h2 id="CLIP-Meets-Video-Captioning-Concept-Aware-Representation-Learning-Does-Matter-2022"><a href="#CLIP-Meets-Video-Captioning-Concept-Aware-Representation-Learning-Does-Matter-2022" class="headerlink" title="CLIP Meets Video Captioning: Concept-Aware Representation Learning Does Matter[2022]"></a>CLIP Meets Video Captioning: Concept-Aware Representation Learning Does Matter[2022]</h2><p>前文提到了captioning的整个pipeline的第一步是用预训练模型提取图像特征，一般使用的预训练模型都是基于图像分类的，而本文将其换成了CLIP并取得了不错的效果。<br>CLIP模型来自论文Learning Transferable Visual Models From Natural Language Supervision[2021], 其框架图和主要流程如下<br><img src="/../images/clip.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># image_encoder - ResNet or Vision Transformer</span></span><br><span class="line"><span class="comment"># text_encoder - CBOW or Text Transformer</span></span><br><span class="line"><span class="comment"># I[n, h, w, c] - minibatch of aligned images</span></span><br><span class="line"><span class="comment"># T[n, l] - minibatch of aligned texts</span></span><br><span class="line"><span class="comment"># W_i[d_i, d_e] - learned proj of image to embed</span></span><br><span class="line"><span class="comment"># W_t[d_t, d_e] - learned proj of text to embed</span></span><br><span class="line"><span class="comment"># t - learned temperature parameter</span></span><br><span class="line"><span class="comment"># extract feature representations of each modality</span></span><br><span class="line">I_f = image_encoder(I) <span class="comment">#[n, d_i]</span></span><br><span class="line">T_f = text_encoder(T) <span class="comment">#[n, d_t]</span></span><br><span class="line"><span class="comment"># joint multimodal embedding [n, d_e]</span></span><br><span class="line">I_e = l2_normalize(np.dot(I_f, W_i), axis=<span class="number">1</span>)</span><br><span class="line">T_e = l2_normalize(np.dot(T_f, W_t), axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># scaled pairwise cosine similarities [n, n]</span></span><br><span class="line">logits = np.dot(I_e, T_e.T) * np.exp(t)</span><br><span class="line"><span class="comment"># symmetric loss function</span></span><br><span class="line">labels = np.arange(n)</span><br><span class="line">loss_i = cross_entropy_loss(logits, labels, axis=<span class="number">0</span>)</span><br><span class="line">loss_t = cross_entropy_loss(logits, labels, axis=<span class="number">1</span>)</span><br><span class="line">loss = (loss_i + loss_t)/<span class="number">2</span></span><br></pre></td></tr></table></figure>

<h2 id="Controllable-Image-Captioning-via-Prompting-2022"><a href="#Controllable-Image-Captioning-via-Prompting-2022" class="headerlink" title="Controllable Image Captioning via Prompting[2022]"></a>Controllable Image Captioning via Prompting[2022]</h2><p>该文将Prompt应用到image captioning上, controllable也一直是研究热点，关于prompt知识可以查阅 Pre-train prompt and predict A systematic survey of prompting methods in natural language processing，不过不得不说这些超大规模的预训练模型一般玩不起。<br><img src="/../images/prompt_caption.png"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/12/10/video-caption/" data-id="cloqxfcny00090wu51uplhgid" data-title="video captioning" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">June 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">March 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">December 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/11/01/%E5%9F%BA%E4%BA%8Epython%E7%9A%84%E6%B5%B7%E5%BA%B7%E6%91%84%E5%83%8F%E5%A4%B4%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/">基于python的海康摄像头二次开发</a>
          </li>
        
          <li>
            <a href="/2023/08/05/%E5%9F%BA%E4%BA%8Epython%E5%8F%8Ac-%E7%9A%84%E6%B5%B7%E5%BA%B7%E6%91%84%E5%83%8F%E5%A4%B4%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/">基于python及c++的海康摄像头二次开发</a>
          </li>
        
          <li>
            <a href="/2023/06/21/%E5%9F%BA%E4%BA%8Epython%E7%9A%84%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97/">基于python的循环队列</a>
          </li>
        
          <li>
            <a href="/2023/04/19/pytorch%E5%8F%8A%E5%85%B6%E4%BB%96%E4%B8%80%E4%BA%9B%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0python%E5%BA%93%E4%BB%8B%E7%BB%8D/">pytorch及其他一些深度学习python库介绍</a>
          </li>
        
          <li>
            <a href="/2023/04/07/m3u8%E8%A7%86%E9%A2%91%E4%B8%8B%E8%BD%BD/">m3u8视频下载</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 sunzx<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>